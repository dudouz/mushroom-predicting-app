# -*- coding: utf-8 -*-
"""Eduardo Rosa Iotti - MVP 4 - Engenharia de Sistemas Inteligentes [OK]

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_W8S-b9osjGstSGHoXa-s2bZCw-HZrHd

Imports

# Configuração **Inicial**
"""

# configuração para não exibir os warnings
import warnings
warnings.filterwarnings("ignore")

# Imports necessários
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC

# normalizador pras categorias qualitativas:
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

# instala o pacote para obter o dataset:
from ucimlrepo import fetch_ucirepo

# instala pickle para exportar o modelo treinado:
import pickle

"""# Carregar **dados**"""

# adicionar o dataset Mushroom de id 73
# https://archive.ics.uci.edu/dataset/73/mushroom
dataset_base = fetch_ucirepo(id=73)

# verificar se a carga está correta, checando o nome do dataset
print(f"Dataset carregado: {dataset_base.metadata.name}")

data = pd.read_csv(dataset_base.metadata.data_url)

"""# Dividir em **conjuntos de teste** e **normalização dos dados**"""

# Define os eixos de características e alvo
# Nesse caso queremos descobrir se o cogumelo é venenos ou comestível
# Dessa forma removemos a coluna 'poisonous' de nosso dataframe ao declararmos as características
# E apontamos específicamente esta coluna como nosso alvo de predição.
X = data.drop('poisonous', axis=1)
y = data['poisonous']

# Como nossas colunas apresentam dados qualitativos representados por iniciais (ou algo similar) de cada
# característica a ser avaliada, utilizaremos o LabelEncoder para nosso alvo de predição e o
# OneHotEncoder para nossas colunas de características.

# Codificar os rótulos categóricos usando o LabelEncoder
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Codificar as características categóricas em X usando OneHotEncoder
onehot_encoder = OneHotEncoder(sparse=False, drop='first')
X_encoded = onehot_encoder.fit_transform(X)

# Normalizar os dados usando o StandardScaler
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_encoded)

test_size = 0.20 # tamanho do conjunto de teste
seed = 7 # semente aleatória

# Dividir o conjunto de dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

# Parâmetros e partições da validação cruzada
scoring = 'accuracy'
num_particoes = 10
kfold = StratifiedKFold(n_splits=num_particoes, shuffle=True, random_state=seed) # validação cruzada com estratificação

"""# Modelagem e **inferência**"""

np.random.seed(7) # definindo uma semente global

# Lista que armazenará os modelos
models = []

# Criando os modelos e adicionando-os na lista de modelos
models.append(('KNN', KNeighborsClassifier()))
models.append(('CART', DecisionTreeClassifier()))
models.append(('NB', GaussianNB()))
models.append(('SVM', SVC()))

# Listas para armazenar os resultados
results = []
names = []

# Mostramos os resultados da avaliação dos modelos
for name, model in models:
  cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
  results.append(cv_results)
  names.append(name)
  print(f"Modelo: {name}, Média: {cv_results.mean()}, Desvio: {cv_results.std()}")

# Geramos um gráfico boxplot para comparar os modelos visualmente:
fig = plt.figure(figsize=(15,10))
fig.suptitle('Boxplot comparativo entre modelos')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names)
plt.show()

"""# Avaliação dos modelos: **Montando e executando as pipelines de normalização e padronização**"""

np.random.seed(7) # definindo uma semente global para este bloco

# Pegamos cada algoritimo já especificado no array de modelos do bloco anterior:
# Verificamos a integridade das informações do array de modelos e o indice de cada algoritimo:
for index, (name, model) in enumerate(models):
  print(f"Modelo: {name}, Indice no array: {index} ", model)

print('--------------------------------------------------------------------------------')

# Criamos as variaveis de acordo com o output interior
knn = models[0]
cart = models[1]
naive_bayes = models[2]
svm = models[3]

# Declaramos os transformers a serem utilizados:
standard_scaler = ('StandardScaler', StandardScaler())
min_max_scaler = ('MinMaxScaler', MinMaxScaler())

# Listas para armazenar os armazenar os pipelines e os resultados para todas as visões do dataset
pipelines = []
results = []
names = []

# Montando os pipelines

# Dataset original:
for index, (name, model) in enumerate(models):
  model_label = f"{name}-orig"
  tuple = (model_label, Pipeline([models[index]]))
  pipelines.append(tuple)

# Dataset Padronizado
for index, (name, model) in enumerate(models):
  model_label = f"{name}-std"
  tuple = (model_label, Pipeline([standard_scaler, models[index]]))
  pipelines.append(tuple)


# # Dataset Normalizado
for index, (name, model) in enumerate(models):
  model_label = f"{name}-norm"
  tuple = (model_label, Pipeline([min_max_scaler, models[index]]))
  pipelines.append(tuple)

# Executando os pipelines
for name, model in pipelines:
    cv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)
    results.append(cv_results)
    names.append(name)
    result = f"Algoritimo: {name}, Média: {cv_results.mean():.3f}, Desvio: {cv_results.std():.3f}"
    print(result)

# Boxplot de comparação dos modelos
fig = plt.figure(figsize=(25,6))
fig.suptitle('Comparação dos Modelos - Dataset orginal, padronizado e normalizado')
ax = fig.add_subplot(111)
plt.boxplot(results)
ax.set_xticklabels(names, rotation=90)
plt.show()

"""# Otimização dos **Hiperparâmetros**"""

# Tuning do KNN

np.random.seed(7)

pipelines = []

# Definindo os componentes do pipeline
knn = ('KNN', KNeighborsClassifier())
standard_scaler = ('StandardScaler', StandardScaler())
min_max_scaler = ('MinMaxScaler', MinMaxScaler())

pipelines.append(('knn-orig', Pipeline(steps=[knn])))
pipelines.append(('knn-padr', Pipeline(steps=[standard_scaler, knn])))
pipelines.append(('knn-norm', Pipeline(steps=[min_max_scaler, knn])))

param_grid = {
    'KNN__n_neighbors': [1,3,5,7,9,11,13,15,17,19,21],
    'KNN__metric': ["euclidean", "manhattan", "minkowski"],
}

# Prepara e executa o GridSearchCV
for name, model in pipelines:
    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)
    grid.fit(X_train, y_train)

    # Aponta a melhor configuração:
    print(f"Sem tratamento de missings: {name} - Melhor Score: {grid.best_score_} usando {grid.best_params_}")

"""# **Finalização** do Modelo"""

# Avaliação do modelo com o conjunto de testes

# Preparação do modelo
scaler = StandardScaler().fit(X_train) # ajuste do scaler com o conjunto de treino
rescaledX = scaler.transform(X_train) # aplicação da padronização no conjunto de treino

# Selecionamos o KNN como modelo treinado, com a métrica manhattan
# Desta forma definimos o modelo abaixo:
model = KNeighborsClassifier(metric='manhattan', n_neighbors=17)
model.fit(rescaledX, y_train)

# Estimativa da acurácia no conjunto de teste
rescaledTestX = scaler.transform(X_test) # aplicação da padronização no conjunto de teste
predictions = model.predict(rescaledTestX)
print(accuracy_score(y_test, predictions))

# Preparação do modelo com TODO o dataset
scaler = StandardScaler().fit(X_encoded) # ajuste do scaler com TODO o dataset
rescaledX = scaler.transform(X_encoded) # aplicação da padronização com TODO o dataset
model.fit(rescaledX, y_encoded)

"""# Testando em **dados desconhecidos**"""

# Novos dados - não sabemos a classe!

# f,s,b,t,f,f,c,b,w,t,b,f,f,w,w,p,w,o,p,h,v,g,p < venenoso
# f,f,e,t,n,f,c,b,w,t,b,s,s,g,w,p,w,o,p,k,v,d,e < comestível

new_mushroom_data = {
    'cap-shape': ['x', 'f'],
    'cap-surface': ['f', 'f'],
    'cap-color': ['g', 'n'],
    'bruises': ['f', 't'],
    'odor': ['f', 'n'],
    'gill-attachment': ['f', 'f'],
    'gill-spacing': ['c', 'c'],
    'gill-size': ['b', 'b'],
    'gill-color': ['g', 'w'],
    'stalk-shape': ['e', 't'],
    'stalk-root': ['b', 'b'],
    'stalk-surface-above-ring': ['k', 's'],
    'stalk-surface-below-ring': ['k', 's'],
    'stalk-color-above-ring': ['b', 'p'],
    'stalk-color-below-ring': ['n', 'p'],
    'veil-type': ['p', 'p'],
    'veil-color': ['w', 'w'],
    'ring-number': ['o', 'o'],
    'ring-type': ['l', 'p'],
    'spore-print-color': ['h', 'n'],
    'population': ['v', 'v'],
    'habitat': ['p', 'd']
}

# Definimos as colunas de características
columns = ['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color', 'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', 'stalk-surface-below-ring', 'stalk-color-above-ring', 'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number', 'ring-type', 'spore-print-color', 'population', 'habitat']

# Normalizamos os dados tal qual fizemos no treinamento do modelo:
mushroom_dataframe = pd.DataFrame(new_mushroom_data, columns=columns)
mushroom_dataframe_encoded = onehot_encoder.transform(mushroom_dataframe)
mushroom_dataframe_scaled = scaler.transform(mushroom_dataframe_encoded)

print(mushroom_dataframe_encoded)

# Padronização nos dados de entrada usando o mesmo scaler utilizado em X anteriormente
X_Input = mushroom_dataframe_scaled.astype(float)
XInputRescaled = scaler.transform(X_Input)

print(XInputRescaled)

# Predição de classes dos dados de entrada
output = model.predict(XInputRescaled)

# 0 venenoso 1 comestível
print(output)

"""# **Exportando** O Modelo"""

# Declaramos aqui o nome do modelo, caminho local a salvarmos o arquivo
# Assim como toda lógica para exportar o modelo treinado usando o pickle:

model_name = "Modelo Treinado - Eduardo Rosa Iotti - KNN - Mushrooms.pkl"

pickle.dump(model, open(model_name, "wb"))